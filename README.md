# 机器翻译数据清洗脚本

## 清洗规则
以下列举了目前支持的清洗规则，可以根据数据情况进行使用，每条规则括号里为使用建议。
### 数据丢弃规则
- 数据去重 （建议保留）
- 丢弃非字符串类型 （建议保留）
- 过滤包含除原文译文外第三方语言的语料 （建议保留，目前第三方语言字符表不太全，只包含部分韩文，俄文，可以根据数据状况补充第三方语言字符）
- 过滤包含乱码的语料 （建议保留，目前乱码词表不太完善，在新的语料中发现对应乱码可以补充乱码词表）
- 过滤过长语料  （建议保留）
- 过滤过短语料 （过短语料一刀切目前不太合理，可以根据所占比例进行部分删减过滤）
- 对齐括号，书名号。括号可以统计原文和译文书名号的数量，如果数量不对齐的可以扔掉。书名号检查中文部分书名号是否闭合。（建议保留）
- 第一次机器清理规则，与公司语料特点相关，不通用。（建议根据语料情况选择性保留）具体规则包括
    - 原文译文相同
    - 英文中包含中文
    - 中文长度大于英文
    - 中文中英文字符比中文字符数
    - 空格占据语料比例在40%以上

### 数据修改规则
- 替换语料中的罗马字符为中文字符 （罗马数字替换目前规则目前不太完善，此数据修改规则可先不使用）
- 对原文和译文的全角半角字符进行转换，中文半角->转全角，拉丁语系全角->半角 （建议保留）
- 处理原文译文尾部标点符号不一致的问题（建议保留）

## 使用示例代码
```py
import pandas as pd
from normalize import NormalizePipline

# 此处获取数据也可从数据库或其他渠道加载，这里以从excel文件中加载为例
data = pd.read_excel("assets/excel_data.xlsx")

pipline = NormalizePipline(data,
                           src_colomn="原文",
                           tgt_colomn="译文",
                           src_lang="zh",
                           tgt_lang="en")

# 丢弃数据
pipline.first_clean_rules(). \
        filter_too_long(). \
        filter_too_short(). \
        filter_3rdlang(). \
        filter_garbled(). \
        normalize_punc(). \
        align_end_punc()

# 获取丢弃的数据
pipline.rubbish
# 获取修改的数据
pipline.modified
# 获取可用的数据 （未修改数据+修改的数据，不包含丢弃的数据）
pipline.data
```